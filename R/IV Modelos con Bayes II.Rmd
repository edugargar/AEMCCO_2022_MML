---
title: "IV Modelos con Bayes II"
output: html_document
date: '2022-07-15'
---

```{r}
load(file = "../R/bayes_primeros_pasos.RData")

if (!require("pacman")) install.packages("pacman")
pacman::p_load("brms", ## paquete principal de estimación bayesiana
               "tidybayes", ## funciones tidy para manejar output de brms
               "bayesplot", ## alternative bayes visualizations
               "tidyverse",
               "easystats",
               "sjPlot",
               "emmeans",
               "ggeffects")
```

# Modelo nulo

Realmente, con las herramientas que tenemos ahora mismo, podemos construir cualquiera de los modelos ya vistos utilizando estimación bayesiana. Esto nos permitirá ganar información, superar limitaciones a la hora de estimar los modelos, y aprender una metodología que nos va a servir para estimar el caso que nosotros queramos.

Vamos a comenzar con el caso más sencillo, el modelo de intercepto aleatorio. En este caso, vamos a comenzar, como vimos previamente, un modelo nulo que nos permita entender si es necesario realizar la modelización con modelos mixtos (o podemos limitarnos a utilizar efectos fijos).

El primer paso es realizar el check de la distribución predictiva a priori. Podéis jugar a cambiar el prior y ver qué consecuencias tiene.

```{r}
prior_user_inf <- c(set_prior("normal(5,2)", class = "Intercept"))
bay_mod_1_null<- brm(??????, 
                        data = data, 
                        warmup = 1000,
                        iter = 2000, 
                        prior = ????,
                        sample_prior = ?????,
                        save_pars = save_pars(all = TRUE),
                        chains = 4,
                        cores = 4,
                        seed = 6)
```
Comprobamos que el modelo ajusta razonablemente a los datos, los parámetros, y el ICC de la distribución a priori...

```{r}
?????(bay_mod_1_null)
```

```{r}
?????(bay_mod_1_null)
```

Podemos utilizar la función `icc` o la función `variance-decomposition`. Personalmente, me parece que esta segunda es mucho más clara para ver los efectos asociados a cada nivel.
```{r}
variance_decomposition(bay_mod_1_null)
```

Vamos a introducir nuestros datos en el modelo, y comprobar qué ocurren con los parámetros estimados a través de la distribución a posteriori.

```{r}
bay_mod_1_null_post <- ?????(bay_mod_1_null,
                                sample_prior = "no",
                                save_pars = save_pars(all = TRUE), 
                                seed = 6)
```

Comprobarmos el valor de los parámetros de la distribución a posteriori y el ajuste...
```{r}
model_parameters(bay_mod_1_null_post)
```

```{r}
pp_check(bay_mod_1_null_post)
pp_check(bay_mod_1_null_post, "stat_2d")
```

Un aspecto clave es conocer el valor del ICC. 

```{r}
?????(bay_mod_1_null_post)
```

Podemos obtener el efecto condicional sobre la media global (u otro parámetro) para la distribución predictiva a priori y la distribución a posteriori. Esto nos podría ayudar a comprobar la influencia del primero sobre el segundo.

```{r}
# Posterior predictions across autonomy
condition_null_prior <- bay_mod_1_null %>% 
  epred_draws(newdata = expand_grid(club_baile = unique(data[data$club_baile %in% (1:10), ]$club_baile)),  re_formula = NULL) %>% 
  add_column(case = "prior")

condition_null_posterior <- bay_mod_1_null_post %>% 
  epred_draws(newdata = expand_grid(club_baile = unique(data[data$club_baile %in% (1:10), ]$club_baile)), re_formula = NULL) %>% 
  add_column(case = "posterior")

condition_effects <- rbind(condition_null_prior, condition_null_posterior)
condition_effects <- condition_effects %>% 
  filter(.draw < 100)

fig2 <- ggplot(condition_effects, 
               aes(x = .epred, 
                   y = "Overall mean",
                   fill = factor(case))) +
  stat_halfeye(
               alpha = 0.4,
               size = 10) +
  facet_wrap(vars(club_baile),
             ncol = 5)+
  xlim(-5,15)+
  labs(x = "Overall expected value", 
       y = NULL,
       subtitle = "Prior conditional effect") +
  theme_bw() +
  theme(legend.position = "bottom")
```

Además, una vez que estimamos la distribución a posteriori, podemos calcular hipótesis direccionales como nosotros prefiramos. Por ejemplo, sobre si el ICC es mayor a 0.

```{r}
hyp <- "sd_club_baile__Intercept^2 / (sd_club_baile__Intercept^2 + sigma^2) > 0"
????(bay_mod_1_null_post, hyp, class = NULL)
```

```{r}
tab_mod_1_no <- tab_model(bay_mod_1_null_post, 
                          show.std = TRUE,
                          title = "Bayesian linear mixed model - null",
                          file = "bayes_null.doc")
tab_mod_1_no
```

Podemos comparar este modelo con el modelo anterior, comprobando cual de ambos tiene un mejor ajuste. Nótese la diferencia en los priors y que falta el predictor entrenamiento en el último modelo.

```{r}
???????(bay_mod_1_prior2_post, 
                    bay_mod_1_null_post)
```

# Modelo de intercepto aleatorio

Vamos a comenzar con la diverisón. De nuevo, vamos a utilizar un sistema de creación del modelo bottom-up. Esto nos permitirá crear modelos de una manera más "controlada", pese al riesgo de inflar el error tipo I.

En este primer paso, vamos a introducir el efecto del entrenamiento (centrado intra-grupo). Es decir, vamos a calcular el efecto de incrementar una unidad de entrenamiento con respecto a la media del grupo sobre la calificación teniendo en cuenta la clase de baile.

```{r}
prior_user_inf <- c(set_prior("normal(5,2)", class = "Intercept"),
                    set_prior("normal(0,2)", class = "b"))

bay_mod_2_ri<- brm(??????, 
                        data = data, 
                        warmup = 1000,
                        iter = 2000, 
                        prior = prior_user_inf,
                        sample_prior = "only",
                        save_pars = save_pars(all = TRUE),
                        chains = 4,
                        cores = 4,
                        seed = 6)
```

Como siempre, vamos a utilizar nuestro tridente de evaluación para comprobar qué tal hemos definido nuestra información previa...

```{r}
pp_check(bay_mod_2_ri)
pp_check(bay_mod_2_ri, "stat_2d")
```

```{r}
?????(bay_mod_2_ri,
  centrality = "mean",
  ci_method = "HDI",
  diagnostic = "all")
```

Comprobamos el modelo de los parámetros
```{r}
model_parameters(bay_mod_2_ri) %>% plot()
```

Calculamos la distribución a posteriori con nuestros datos y la función ¿qué función?...

```{r}
bay_mod_2_ri_post <- ?????(bay_mod_2_ri,
                                sample_prior = "no",
                                save_pars = save_pars(all = TRUE), 
                                seed = 6)
summary(bay_mod_2_ri_post)
```

Lo primero, vamos a comprobar que el modelo a ajustado correctamente, y que nos proporciona mejor ajuste que el modelo nulo (si no lo hiciera, no tendría sentido continuar)

```{r}
pp_check(bay_mod_2_ri_post)
pp_check(bay_mod_2_ri_post, "stat_2d")
```

```{r}
compare_performance(bay_mod_1_null_post, bay_mod_2_ri_post)
```

Comprobamos que las diferencias entre la distribución predictiva a priori y a posteriori, observando si puede ser razonable ajustar las distribuciones a priori que hemos impouesto en nuestros datos.

```{r}

condition_null_prior <- bay_mod_2_ri %>% 
  epred_draws(newdata = expand_grid(club_baile = unique(data[data$club_baile %in% (10:14), ]$club_baile), entrenamiento_within = seq(-3,3, by = 1)), re_formula = NULL) %>% 
  add_column(case = "prior")

condition_null_posterior <- bay_mod_2_ri_post %>% 
   epred_draws(newdata = expand_grid(club_baile = unique(data[data$club_baile %in% (10:14), ]$club_baile), entrenamiento_within = seq(-3,3, by = 1)), re_formula = NULL) %>% 
  add_column(case = "posterior")

condition_effects <- rbind(condition_null_prior, condition_null_posterior)
condition_effects <- condition_effects %>% 
  filter(.draw < 100)

fig3 <- ggplot(condition_effects, 
               aes(x = entrenamiento_within, 
                   y = .epred)) +
  stat_lineribbon(.width = c(0.8, 0.95),)+
  scale_fill_brewer(palette = "Blues") +
  facet_wrap(vars(case, club_baile),
             ncol = 5)+
  theme_bw() +
  theme(legend.position = "bottom")
```

Si queremos realizar una inspección detallada del efecto del entrenamiento, podemos utilizar `describe_posterior`

```{r}
model_parameters(bay_mod_2_ri_post) %>% plot()
describe_posterior(bay_mod_2_ri_post,
  centrality = "mean",
  ci_method = "HDI",
  diagnostic = "all")
```

Y, por último, podemos ir guarando todos nuestros progresos en una tabla para poder copiar y pegar en nuestro paper.

```{r}
tab_mod_2_ri <- tab_model(bay_mod_1_null_post,
                          bay_mod_2_ri_post,
                          show.std = TRUE,
                          title = "Bayesian linar non-mixed model",
                          file = "bayes1.doc")
tab_mod_2_ri
```

Podemos comparar qué hubiera pasado si hubiéramos aplicado por priors establecidos por defecto en brms. Para ello, ajustamos un modelo sin información previa.

```{r}
bay_mod_2_def<- brm(????????, 
                        data = data, 
                        warmup = 1000,
                        iter = 2000, 
                        save_pars = save_pars(all = TRUE),
                        chains = 4,
                        cores = 4,
                        seed = 6)
```

```{r}
pp_check(bay_mod_2_def)
compare_performance(bay_mod_2_ri_post, bay_mod_2_def)
model_parameters(bay_mod_2_ri_post, bay_mod_2_def)
```

## Construir el modelo de pendientes aleatorias.

## Construir el modelo con el efecto contextual.

## Incluir un predictor de primer nivel (genero - sex) y un predictor del segundo nivel (experiencia del entrenador -exp_entrenador).

## Incluir la interacción internivel entre ambas variables

# Bonus: Observando los efectos del partial pooling

```{r}

bay_mod_1_no_alt <- brm(calificacion ~ entrenamiento_within + club_baile, 
                        data = data, 
                        warmup = 1000,
                        iter = 2000, 
                        prior = prior_user_inf,
                        chains = 4,
                        cores = 4,
                        save_pars = save_pars(all = TRUE),
                        seed = 6)


bay_mod_2<- brm(calificacion ~ entrenamiento_within + (1 +entrenamiento_within| club_baile),
                data = data,
                warmup = 1000,
                iter = 2000,
                #prior = prior_user_inf2,
                chains = 4,
                cores = 4,
                save_pars = save_pars(all = TRUE),
                seed = 6)


bmod1_pooled <-
  fixef(bay_mod_2)[, 1] %>%
  as.matrix %>%
  t

complete_pooling <-
  data.frame(
    club_baile = unique(data$club_baile),
    Intercept = bmod1_pooled[1],
    entrenamiento_within = bmod1_pooled[2],
    model = "complete_pooling")

no_pooling <-
  lme4::lmList(calificacion ~ entrenamiento_within|club_baile, data = data) %>%
  coef() %>%
  rownames_to_column("club_baile") %>%
  mutate(model = "no pooling") %>%
  rename(Intercept = `(Intercept)`)

partial_pooling <- 
  coef(bay_mod_2)$club_baile[, 1, ] %>%
  data.frame %>%
  rownames_to_column("club_baile") %>%
  mutate(model = "partial pooling")

shrinkage <- bind_rows(no_pooling, partial_pooling)

# Extracting posterior samples
post <- posterior_samples(bay_mod_2, pars = c("^b_", "^sd", "^cor") )

# Computing posterior mean bivariate Gaussian
mu <- c(mean(post$b_Intercept), mean(post$b_entrenamiento_within) )
rho <- mean(post$cor_club_baile__Intercept__entrenamiento_within)
sda <- mean(post$sd_club_baile__Intercept)
sdb <- mean(post$sd_club_baile__entrenamiento_within)
cov_ab <- sda * sdb * rho
cov_ab <- sda 
sigma <- matrix(c(sda^2, cov_ab, cov_ab, sdb^2), ncol = 2)
#sigma <- cov_ab

###########################################################################################
# Helper function to make ellipse, credits to Tristan Mahr
# https://tjmahr.github.io/plotting-partial-pooling-in-mixed-effects-models/
##################################################################################


shrinkage %>%
  ggplot(aes(x = Intercept, 
             y = entrenamiento_within, 
             color = model) ) +
  scale_color_ordinal(begin = 1, end = 0)+
  geom_path(aes(group = club_baile, color = NULL), show.legend = FALSE ) +
  ggrepel::geom_text_repel(
    aes(label = club_baile, color = NULL),
    data = no_pooling, show.legend = FALSE
  ) +
  geom_point(size = 2, show.legend = TRUE) +
  geom_smooth(method = "lm")+
  geom_point(
    data = complete_pooling,
    aes(x = Intercept, 
        y = entrenamiento_within),
    size = 2, color = "red",
    show.legend = FALSE, inherit.aes = FALSE
  ) +
  coord_cartesian(
    xlim = c(min(shrinkage$Intercept), max(shrinkage$Intercept) ),
    ylim = c(min(shrinkage$entrenamiento_within), max(shrinkage$entrenamiento_within) ),
    expand = TRUE) +
  theme_bw(base_size = 10)


```
