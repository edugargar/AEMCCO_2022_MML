---
title: "3. Modelos Bayesianos I"
output: html_document
date: '2022-07-14'
---

Este cuaderno contiene nuestros primeros pasos realizando análisis linear mixtos utilizando estadística bayesiana. En este cuaderno vamos a seguir los mismos pasos que los seguidos en los cuadernos I y II de análisis con lme4, pero adaptándolo a un nuevo ejemplo y a las características de estos modelos.

Todos los ejemplos se realizarán con la base de datos "Ejemplo 6 escuelas.csv". Este ejemplo está adaptado del siguiente blog de [Rens van de Schoot](https://www.rensvandeschoot.com/tutorials/brms-started/), cambiando los nombres de las variables y adaptando el dataset. La base de datos contiene la siguiente información:

1)  id = identificador del alumno.
2)  club_baile = id del club de baile al que acude.
3)  entrenamiento = horas de entrenamiento.
4)  sex = género (0 mujeres, 1 hombre)
5)  calificación = puntuación en la última competición
6)  exp_entrenador = experiencia del entrenador
7)  pop_entrenador = popularidad del entrenador.

# Preprocesamiento de la información

Cargamos los paquetes necesarios para poder realizar los cálculos.

```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load("brms", ## paquete principal de estimación bayesiana
               "tidybayes", ## funciones tidy para manejar output de brms
               "bayesplot", ## alternative bayes visualizations
               "tidyverse",
               "easystats",
               "sjPlot",
               "emmeans",
               "ggeffects",
               "shinystan")
```

## Centramos los predictores.

En este caso, vamos a utilizar una estrategia de centrado por media del grupo para las variables del primer nivel. Además, calculamos las variables contextuales correspondientes (mismas variables centradas por la media global). En este caso, no estandarizamos la variable dependiente para facilitar la interpretación de los resultados en años, no en desviaciones típicas.

```{r}
data <- read_csv2('https://raw.githubusercontent.com/edugargar/Curso_AEMCCO_2022_MML/main/datasets/csv/Example%206%20baile.csv')
centered_vars <- demean(data, select = c("entrenamiento"), group = "club_baile")
data <- cbind(data, centered_vars)
data <- data %>% mutate(calificacion = as.numeric(calificacion))
```

# Modelos lineales bayesianos (no mixtos)

Para poder explorar correctamente las propiedades de la estimación bayesiana, y conocer más de cerca sus componentes, vamos a utilizar modelos lineales (no mixtos). Esto nos permitirá entender la influencia de la información previa, conocer cómo funciona el sampleador NUTS, y como extraer estadísticos de interés.

Lo primero que tenemos que entender es que en el caso de la estimación, los métodos de estimación se realizan mediante métodos MCMC. Esta situación indica que tenemos que ejercer un mayor control sobre el método de estimación que en otro tipo de optimización (p.ej., en lme4 cuando cambiamos de optimizador).

Vamos a realizar nuestro primer ejemplo. En el mismo, vamos a solicitar a brms que nos realize un modelo de pooling parcial (es decir, un modelo de regresión lineal sin efectos aleatorios). La sintaxis de brms es similar a la de lme4. Sin embargo, tendremos que añadir 4 nuevos parámetros (warmup, iter, chains, cores).

¿Qué ocurre si intentamos estimar este modelo?

```{r}
bay_mod_1_no <- brm(calificacion ~ entrenamiento, 
                data = data, 
                warmup = 100,
                iter = 200, 
                chains = 4,
                cores = 4)
```

En este caso, se nos está indicando que el ESS (tail effective sample size) es muy pequeño. Podemos ver exactamente los valores, como en lme4, haciendo un summary del objeto. Además, podemos comprobar otra información importante, como...

```{r}
summary(bay_mod_1_no)
```

-   la función de unión es de identidad con un likelihood normal, lo que indica que estamos ante una regresión lineal estándar.

-   Vemos que el TAIL_ESS es muy limitado \~ 300. Tenemos que probar a aumentar el número de iteracciones para estimar correctamente nuestro modelo.

-   Además, otro aspecto importante es que vemos varios parámetros con Rhat \> 1.01. Esto nos podría indicar que la cadena subyacente a la estimación no ha convergido a un valor único.

-   Por último, cuidado con los CI. En este caso son intervalos de credibilidad, no intervalos de confianza.

Podemos probar a re-estimar nuestro modelo, esta vez aumentando el número de iteracciones con la que vamos a aproximar este modelo, observando si ahora obtenemos algún problema. ¿Han cambiado realmente la estimación de nuestros parámetros?

```{r}
bay_mod_1_no <- brm(calificacion ~ entrenamiento, 
                data = data, 
                warmup = 1000,
                iter = 2000, 
                chains = 4,
                cores = 4)
summary(bay_mod_1_no)
```

Lo bueno que tiene utilizar ciertos wrappers incluídos en paquetes como *easystats* es que están adaptados a todo tipo de modelos, incluídos los estimados con brms. En este sentido, vamos a poder utilizar muchas de las funciones que ya conocíamos previamente para cosas como obtener los parámetros estimados (utilizando la mediana de la distribución a posteriori de cada uno de los parámetros y los intervalos de credibilidad).

```{r}
model_parameters(bay_mod_1_no) %>% plot()
```

... comprobar el ajuste de nuestro modelo (en este caso, la estimación es más lenta debido al cálculo del LOOIC) ....

```{r}
performance(bay_mod_1_no)
```

... o comprobar la ideonidad de nuestro modelo...

```{r}
check_model(bay_mod_1_no)
```

Además, tenemos una serie de comprobaciones adicionales que podemos realizar para entender que nuestro modelo se ha estimado correctamente. Lo primero es comprobar que nuestras 4 cadenas se han mezclado correctamente. En este caso, podemos utilizar la función plot para acceder directamente a esta información...

```{r}
plot(bay_mod_1_no)
```

Por otra parte, brms tiene incoporado un método que nos permite examinar diferentes aspectos del modelo.

```{r}
pp_check(bay_mod_1_no, type = "xyz")
pp_check(bay_mod_1_no, type = "dens")
pp_check(bay_mod_1_no, type = "boxplot")
pp_check(bay_mod_1_no, type = "looic")
pp_check(bay_mod_1_no, type = "stat_2d")
pp_check(bay_mod_1_no, type = "loo_intervals")
```

De nuevo, si comprobamos que todo está correcto, podemos crear una tabla que nos ofrezca toda la información traicionalmente requerida por nuestros queridos revisores 2.

```{r}
tab_mod_1_no <- tab_model(bay_mod_1_no, 
                          show.std = TRUE,
                          title = "Bayesian linar non-mixed model",
                          file = "bayes1.doc")
tab_mod_1_no
```

Una herramienta muy útil para "jugar" con los detalles de un modelo es `shinystan`. Esta aplicación contiene herramientas muy avanzadas para poder ver si un modelo se ha estimado correctamente, y la estimación de las distribuciones a posteriori.

```{r}
shinystan::launch_shinystan(bay_mod_1_no)
```

# El diablo está en los detalles

Hasta ahora, no parece que hacer estadística bayesiana sea muy complejo. Ponemos un montón de interacciones, buscamos en google que es "LOOIC" y reutilizamos las funciones previamente conocidas. Easy peasy.

Sin embargo, no hemos entrado todavía en ciertos aspectos fundamentales de este tipo de análisis. Por un lado, hemos comprobado que brms ha estimado una distribución a posteriori únicamente indicando el likelihood. ¿Dónde quedaron nuestras distribuciones previas?

```{r}
prior_summary(bay_mod_1_no)
```

En este caso, podemos ver que los parámetros de regresión reciben distribuciones previas impropias, mientras que los parámetros del intercepto y la varianza reciben distribuciones propias robustas adaptadas a la escala de la variable dependiente. Un detalle importante sobre el prior relativo al intercepto es que..

**"general priors on class `"b"` will *not* affect the intercept [...]Note that technically, this prior is set on an intercept that results when internally centering all population-level predictors around zero to improve sampling efficiency. On this centered intercept, specifying a prior is actually much easier and intuitive than on the original intercept, since the former represents the expected response value when all predictors are at their means. To treat the intercept as an ordinary population-level effect and avoid the centering parameterization, use `0 + Intercept` on the right-hand side of the model formula.".**

Sobre el prior de la varianza residual, es importante saber que está truncado en 0, y que normalmente recibe un parámetro de escala equivalente a la mitad de la desviación típica de la variable de respuesta (después de aplicar la función de unión corresponiente) o, como mínimo, 2.5 puntos.

Cuando hablamos de fijar los priors, siempre conviene visualizarlos. Vamos a ver qué información estamos indicando sobre nuestro intercepto y nuestra desviación típica:

```{r}
prior1 <- data.frame("prior" = rstudent_t(3000, 3, mu = 0, sigma = 2.5))
prior1$type <- "prior1"
prior2 <- data.frame("prior" = rnorm(3000,0, 1))
prior2$type <- "prior2"
priors <- rbind(prior1, prior2)
ggplot(priors, aes(prior, fill = type)) + stat_halfeye(alpha = 0.8) +
  theme_bw()
```

Podemos comparar asimismo cuál serían los valores esperados bajo diferentes distribuciones que pudiéramos pensar...

```{r}
draws <- 1000
norm_df <- as_tibble(data.frame(sd_1 = rnorm(draws, mean = 0, sd = .33),
                                sd_2 = rnorm(draws, mean = 0, sd = 1),
                                sd_5 = rnorm(draws, mean = 0, sd = 3))) %>%
  pivot_longer(cols = c(sd_1, sd_2, sd_5), names_to = "prior", values_to = "samples")

ggplot(norm_df, aes(y = fct_rev(prior), x=samples, fill = stat(abs(x) < 2.8))) + 
  stat_halfeye() +
  scale_fill_manual(values = c("gray80", "skyblue")) +
  labs(title = "Distribuciones normales",
       x = "densidad",
       y  = "stdev")
```

Es necesario que establezcamos un prior propio sobre todos los parámetros si queremos analizar ciertos estadísticos de interés (como factores de bayes, etc.). Como primer ejemplo, vamos a establecer un prior muy,muy informativo sobre los parámetros de regresión, y comprobar su influencia.

A la hora de estudiar la información previa, una herramienta clave es la distribución previa a priori. En ella, sampleamos un modelo estadístico únicamente teniendo en cuenta todas las distribuciones previas (sin tener en cuenta el likelihood).

```{r}
prior_user_inf <- c(set_prior("normal(0,.01)", class = "b"))

job::job({
  bay_mod_1_prior<- brm(calificacion ~ entrenamiento, 
                    data = data, 
                    warmup = 1000,
                    iter = 2000, 
                    prior = prior_user_inf,
                    sample_prior = "only",
                    chains = 4,
                    cores = 4,
                    seed = 6)
}, import = c(data, prior_user_inf))

```

Podemos obtener los efectos condicionales (predichos) para este modelo que contiene únicamente la información previa.

```{r}
fig1 <- plot(ggpredict(bay_mod_1_prior),
             add.data = T,
             facet = TRUE)
```

Como vemos, tenemos una fuerte influencia previa que indica que el efecto esperado de entrenamiento sobre la calificación es cercana a 0. ¿Qué pasaría si hubiéramos especificado una distribución previa menos informativa?

```{r}
prior_user_inf2 <- c(set_prior("normal(0,10)", class = "b"))

bay_mod_1_prior2<- brm(calificacion ~ entrenamiento, 
                    data = data, 
                    warmup = 1000,
                    iter = 2000, 
                    prior = prior_user_inf2,
                    sample_prior = "only",
                    chains = 4,
                    cores = 4,
                    seed = 6)

fig2a <- plot(ggpredict(bay_mod_1_prior2),
             add.data = T,
             facet = TRUE)
```

a vez que hemos compilado nuestro modelo, podemos actualizalo con los datos para generar las distribuciones a posteriori. Podemos utilizar la función `update` para ello.

```{r}
bay_mod_1_prior_post <- update(bay_mod_1_prior,
                                sample_prior = "no",
                                save_pars = save_pars(all = TRUE), 
                                seed = 6)

fig3 <- plot(ggpredict(bay_mod_1_prior_post),
             add.data = T,
             facet = TRUE)

bay_mod_1_prior2_post <- update(bay_mod_1_prior2,
                                sample_prior = "no",
                                save_pars = save_pars(all = TRUE),
                                seed = 6)
fig4 <- plot(ggpredict(bay_mod_1_prior2_post),
             add.data = T,
             facet = TRUE)

fig34 <- fig3 + fig4
```

¿Y cómo decidimos con qué modelo nos quedamos?....

```{r}
compare_performance(bay_mod_1_prior_post, bay_mod_1_prior2_post)
```

Podemos calcular la influencia de la distribución previa sobre la posterori utilizando el paquete `bayesplot`

```{r}
plot(bayesfactor_parameters(bay_mod_1_prior_post))
plot(bayesfactor_parameters(bay_mod_1_prior2_post))
```

Y, por último, podemos obtener la distribución predictiva a posteriori. Esta distribución nos permite obtener una mejor idea de los efectos encontrados y evaluarlos en términos de dirección, incertidumbre, etc.

```{r}
fig5 <- data %>%
    add_predicted_draws(bay_mod_1_prior2_post) %>%  # adding the posterior distribution
    ggplot(aes(x = entrenamiento, 
               y = calificacion)) +  
    stat_lineribbon(aes(y = .prediction), 
                    .width = c(.95, .80, .50),  # regression line and CI
                    alpha = 0.5, 
                    colour = "black") +
    geom_point(data = data, 
               colour = "darkseagreen4", 
               size = 3) +   # raw data
    scale_fill_brewer(palette = "Greys") +
    ylab("Calidris canutus abundance\n") +  # latin name for red knot
    xlab("\nYear") +
    theme_bw() +
    theme(legend.title = element_blank(),
          legend.position = c(0.15, 0.85))


```

## Interpretación de los modelos

Una de las cuestiones más complejas, pero divertidas, de trabajar con estadística bayesiana, es la posibilidad de realizar inferencias desde diferentes perspectivas. En estadística frecuentista, nuestro mejor amigo es el **valor p.** Sin embargo, aquí no vamos a tener (por suerte) que confiar únicamente en los valores de p para tomar decisiones.

Uno de los primeros elementos que vamos a poder analizar son los intervalos de credibilidad. A diferencia de un intervalo de confianza (que se construyen sobre la prob. de que el parámetro se sitúe dentro de un intervalo de X rango, pero de límites desconocidos), aquí podemos interpretar los mismos como el intervalo (determinado por la distribución a posterori) en el que existe una probabilidad X de que el parámetro de interés se sitúe. Si queremos obtenerlos, podemos verlos como...

```{r}
model_parameters(bay_mod_1_prior_post)
model_parameters(bay_mod_1_prior2_post)
```

Sin embargo, esto no son los únicos tipos de intervalo que podemos contruir. Otros interavlos muy importantes son los HDI o intervalos de alta densidad. En los mismos, calculamos la región de la distribución a posteriori que captura el 95% de los casos. Importante, en este caso no es necesario observar un intervalo con una distribución con colas simétricas, ya que depende de la distribución a posterori...

```{r}
ci(bay_mod_1_prior2_post, method = "CI", ci = .89)
ci(bay_mod_1_prior2_post, method = "HDI", ci = .89)
```

Hay autores que interpretan este tipo de intervalos con respecto a un único valor nulo (e.g., 0) para determinar si se ha observado o no se ha observado un determinado efecto. Sin embargo, este tipo de tests son bastante limitados (straw-man test) y ahora que tenemos toda la distribución a posteriori calculada, podemos realizar cosas más interesantes.

Un primer detalle que suele comprobarse, es la probabilidad de dirección (o % de las distribuciones a posteriori estimadas que tienen un determinado valor). También podemos realizar este test directamente sobre los parámetros utilizando la flexible función `hypothesis` de brms.

```{r}
plot(p_direction(bay_mod_1_prior2_post))
hypothesis(bay_mod_1_prior2_post, "b_entrenamiento > 0", class = NULL)
plot(hypothesis(bay_mod_1_prior2_post, "b_entrenamiento > 0", class = NULL))
```

Existen, por último, dos estimandos que son de especial interés dentro de la literatura bayesiana: a) las regiones de equivalencia práctica; b) los factores de bayes. Los primeros son equivalentes a un ratio de densidad de la distribución a posteriori dentro vs. fuera de un rango determinado. Para los ropes es clave definir un intervalo de interés. Si no tenemos ni idea, quizás no sea la mejor herramienta. Existen maneras "automáticas" de definir este rope:

**Kruschke (2018) suggests that such null value could be set, by default, to the -0.1 to 0.1 range of a standardized parameter (negligible effect size according to Cohen, 1988). This could be generalized: For instance, for linear models, the ROPE could be set as `⁠0 +/- .1 * sd(y)⁠`. This ROPE range can be automatically computed for models using the [rope_range](http://127.0.0.1:57662/help/library/bayestestR/help/rope_range) function.**

Los segundos indican cúanto más probable es el valor de un parámetro en la distrubución a posteriori vs. distribución a priori. Como ambos son sensibles a diferentes elementos, normalmente suelen informarse de manera complementaria (y no están exentos de polémicas). Ambos elementos pueden combinarse (calcular un BF sobre ROPE), y aunque es una técnica poco común, está ganando adeptos.

```{r}
plot(rope(bay_mod_1_prior_post, method = "HDI", range = c(-.1, .1)))
plot(rope(bay_mod_1_prior2_post, method = "HDI", range = c(-.1, .1)))
plot(rope(bay_mod_1_prior2_post, method = "HDI", range = rope_range(bay_mod_1_prior2_post)))
```

```{r}
bayesfactor_parameters(bay_mod_1_prior_post)
bayesfactor_parameters(bay_mod_1_prior2_post)
bayesfactor_parameters(bay_mod_1_prior2_post, direction = ">")
bayesfactor_models(bay_mod_1_prior_post, bay_mod_1_prior2_post)
```

Una forma alternativa de obtener toda esta información es la función `describe_posterior`

```{r}
describe_posterior(
  rowMeans(fitted(bay_mod_1_prior2_post, 
                  summary = FALSE)),
  centrality = "mean", 
  ci_method = "HDI")
```

```{r}
save(data,
     bay_mod_1_prior2_post,
     file = "../R/bayes_primeros_pasos.RData")
```
